{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B√ÄI T·∫¨P V·ªÄ NH√Ä - OPENCV V·ªöI PYTHON\n",
    "\n",
    "**L∆∞u √Ω**: C√≥ nh·ªØng ki·∫øn th·ª©c ch∆∞a ƒë∆∞·ª£c cung c·∫•p tr√™n l·ªõp anh ƒë√£ note l·∫°i ·ªü t·ª´ng b√†i c√°c b·∫°n c√≥ ch·ªß ƒë·ªông t√¨m hi√™u, nh·ªØng ph·∫ßn m√† ch∆∞a ki·∫øn th·ª©c ƒë√≥ anh ƒë√£ ƒë·ªÉ lu√¥n code v·∫≠y n√™n c√°c em c√≥ th·ªÉ s·ª≠ d·ª•ng ch√∫ng ƒë·ªÉ research th√™m\n",
    "\n",
    "**M√¥ t·∫£**: Notebook n√†y bao g·ªìm c√°c b√†i t·∫≠p th·ª±c h√†nh OpenCV t·ª´ c∆° b·∫£n ƒë·∫øn n√¢ng cao. M·ªói b√†i t·∫≠p c√≥ ƒë·ªÅ b√†i r√µ r√†ng v√† code m·∫´u gi·∫£i ƒë√°p.\n",
    "\n",
    "**Y√™u c·∫ßu**:\n",
    "- Python 3.x\n",
    "- OpenCV (`pip install opencv-python`)\n",
    "- NumPy (`pip install numpy`)\n",
    "- Matplotlib (`pip install matplotlib`)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.12.0\n",
      "2.2.6\n",
      "3.10.8\n"
     ]
    }
   ],
   "source": [
    "# !pip install opencv-python\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib as m\n",
    "\n",
    "print(cv.__version__)\n",
    "print(np.__version__)\n",
    "print(m.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PH·∫¶N 1: C∆† B·∫¢N (BASICS)\n",
    "\n",
    "### B√†i 1: ƒê·ªçc v√† Hi·ªÉn th·ªã ·∫¢nh, Video\n",
    "\n",
    "**ƒê·ªÅ b√†i:**\n",
    "1. ƒê·ªçc v√† hi·ªÉn th·ªã ·∫£nh t·ª´ file `Resources/Photos/cats.jpg`\n",
    "2. ƒê·ªçc v√† hi·ªÉn th·ªã video t·ª´ file `Resources/Videos/dog.mp4`\n",
    "3. Cho ph√©p ng∆∞·ªùi d√πng nh·∫•n ph√≠m 'd' ƒë·ªÉ tho√°t kh·ªèi video\n",
    "\n",
    "**M·ª•c ti√™u h·ªçc t·∫≠p:**\n",
    "- S·ª≠ d·ª•ng `cv.imread()` ƒë·ªÉ ƒë·ªçc ·∫£nh\n",
    "- S·ª≠ d·ª•ng `cv.VideoCapture()` ƒë·ªÉ ƒë·ªçc video\n",
    "- Hi·ªÉu v·ªÅ v√≤ng l·∫∑p ƒë·ªçc video frame-by-frame\n",
    "- Qu·∫£n l√Ω t√†i nguy√™n v·ªõi `release()` v√† `destroyAllWindows()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ho√†n th√†nh b√†i 1!\n"
     ]
    }
   ],
   "source": [
    "### CODE GI·∫¢I B√ÄI 1\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "# Ph·∫ßn 1: ƒê·ªçc v√† hi·ªÉn th·ªã ·∫£nh\n",
    "img = cv.imread('Resources/Photos/cats.jpg')\n",
    "cv.imshow('photo', img)\n",
    "cv.waitKey(0)\n",
    "# Ph·∫ßn 2: ƒê·ªçc v√† hi·ªÉn th·ªã video\n",
    "\n",
    "vd = cv.VideoCapture('Resources/Videos/dog.mp4')\n",
    "\n",
    "while True:\n",
    "    isTrue, frame  = vd.read()\n",
    "\n",
    "    if not isTrue:\n",
    "        break\n",
    "\n",
    "    cv.imshow('video', frame)\n",
    "\n",
    "    if cv.waitKey(20) == ord('d'):\n",
    "        break\n",
    "\n",
    "# Gi·∫£i ph√≥ng t√†i nguy√™n\n",
    "vd.release()\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "print(\"Ho√†n th√†nh b√†i 1!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### B√†i 2: V·∫Ω H√¨nh v√† Vi·∫øt Ch·ªØ\n",
    "\n",
    "**ƒê·ªÅ b√†i:**\n",
    "1. T·∫°o m·ªôt canvas tr·∫Øng k√≠ch th∆∞·ªõc 500x500 pixels\n",
    "2. V·∫Ω m·ªôt h√¨nh ch·ªØ nh·∫≠t m√†u xanh l√° c√¢y ·ªü g√≥c tr√™n b√™n tr√°i\n",
    "3. V·∫Ω m·ªôt h√¨nh tr√≤n m√†u ƒë·ªè ·ªü gi·ªØa canvas\n",
    "4. V·∫Ω m·ªôt ƒë∆∞·ªùng th·∫≥ng m√†u tr·∫Øng\n",
    "5. Vi·∫øt text \"OpenCV Tutorial\" l√™n canvas\n",
    "6. T√¥ m·ªôt v√πng nh·ªè m√†u ƒë·ªè tr√™n canvas b·∫±ng array slicing\n",
    "\n",
    "**M·ª•c ti√™u h·ªçc t·∫≠p:**\n",
    "- T·∫°o blank image v·ªõi NumPy\n",
    "- S·ª≠ d·ª•ng `cv.rectangle()`, `cv.circle()`, `cv.line()`\n",
    "- S·ª≠ d·ª•ng `cv.putText()` ƒë·ªÉ vi·∫øt text\n",
    "- Hi·ªÉu v·ªÅ m√†u s·∫Øc BGR trong OpenCV\n",
    "- S·ª≠ d·ª•ng array slicing ƒë·ªÉ thay ƒë·ªïi pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ho√†n th√†nh b√†i 2!\n"
     ]
    }
   ],
   "source": [
    "### CODE GI·∫¢I B√ÄI 2\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# T·∫°o canvas tr·∫Øng 500x500 pixels, 3 channels (BGR)\n",
    "\n",
    "blank = np.zeros((500, 500, 3), dtype='uint8')\n",
    "blank[:] = 255,255,255\n",
    "# 1. T√¥ m·ªôt v√πng m√†u ƒë·ªè (BGR: 0,0,255)\n",
    "\n",
    "blank[0:250, 0 : 250] = 0,0,255\n",
    "\n",
    "\n",
    "# 2. V·∫Ω h√¨nh ch·ªØ nh·∫≠t m√†u xanh l√° (BGR: 0,255,0)\n",
    "# Tham s·ªë: image, ƒëi·ªÉm b·∫Øt ƒë·∫ßu, ƒëi·ªÉm k·∫øt th√∫c, m√†u, ƒë·ªô d√†y (-1 = fill)\n",
    "\n",
    "cv.rectangle(blank, (100, 100), (300, 300), (0, 255, 0), thickness=-1)\n",
    "# 3. V·∫Ω h√¨nh tr√≤n m√†u ƒë·ªè ·ªü gi·ªØa\n",
    "# Tham s·ªë: image, t√¢m, b√°n k√≠nh, m√†u, ƒë·ªô d√†y\n",
    "cv.circle(blank, (400, 200), 50, (0, 255, 0), thickness= 1)\n",
    "# 4. V·∫Ω ƒë∆∞·ªùng th·∫≥ng m√†u tr·∫Øng\n",
    "# Tham s·ªë: image, ƒëi·ªÉm b·∫Øt ƒë·∫ßu, ƒëi·ªÉm k·∫øt th√∫c, m√†u, ƒë·ªô d√†y\n",
    "cv.line(blank, (0, 0), (400, 400), (0, 255, 0), thickness=4)\n",
    "# 5. Vi·∫øt text\n",
    "# Tham s·ªë: image, text, v·ªã tr√≠, font, font scale, m√†u, ƒë·ªô d√†y\n",
    "\n",
    "cv.putText(blank, 'hello', (450, 450), cv.FONT_HERSHEY_PLAIN, 1.0, (100, 240, 0), thickness= 2)\n",
    "cv.imshow('blank', blank)\n",
    "cv.waitKey(0)\n",
    "print(\"Ho√†n th√†nh b√†i 2!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### B√†i 3: C√°c H√†m C∆° B·∫£n trong OpenCV\n",
    "\n",
    "**ƒê·ªÅ b√†i:**\n",
    "√Åp d·ª•ng c√°c ph√©p bi·∫øn ƒë·ªïi sau l√™n ·∫£nh `Resources/Photos/park.jpg`:\n",
    "1. Chuy·ªÉn ƒë·ªïi sang ·∫£nh grayscale (x√°m)\n",
    "2. L√†m m·ªù ·∫£nh b·∫±ng Gaussian Blur v·ªõi kernel 7x7\n",
    "3. Ph√°t hi·ªán c·∫°nh b·∫±ng Canny Edge Detection\n",
    "4. L√†m d√†y (dilate) c√°c c·∫°nh ƒë√£ ph√°t hi·ªán\n",
    "5. L√†m m·ªèng (erode) ·∫£nh ƒë√£ dilate\n",
    "6. Resize ·∫£nh v·ªÅ k√≠ch th∆∞·ªõc 500x500\n",
    "7. C·∫Øt (crop) m·ªôt v√πng c·ªßa ·∫£nh\n",
    "\n",
    "**M·ª•c ti√™u h·ªçc t·∫≠p:**\n",
    "- Chuy·ªÉn ƒë·ªïi color space v·ªõi `cv.cvtColor()`\n",
    "- L√†m m·ªù ·∫£nh v·ªõi `cv.GaussianBlur()`\n",
    "- Ph√°t hi·ªán c·∫°nh v·ªõi `cv.Canny()`\n",
    "- Morphological operations: `cv.dilate()`, `cv.erode()`\n",
    "- Resize v√† crop ·∫£nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ho√†n th√†nh b√†i 3!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "### CODE GI·∫¢I B√ÄI 3\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "# ƒê·ªçc ·∫£nh\n",
    "img = cv.imread('Resources/Photos/park.jpg')\n",
    "# 1. Chuy·ªÉn ƒë·ªïi sang grayscale\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('xam', gray)\n",
    "# 2. L√†m m·ªù v·ªõi Gaussian Blur\n",
    "# Tham s·ªë: image, kernel size (ph·∫£i l√† s·ªë l·∫ª), border type\n",
    "blur = cv.GaussianBlur(img, (7,7), cv.BORDER_DEFAULT)\n",
    "cv.imshow('mo', blur)\n",
    "# 3. Ph√°t hi·ªán c·∫°nh v·ªõi Canny\n",
    "# Tham s·ªë: image, threshold1, threshold2\n",
    "canny = cv.Canny(blur, 120, 175)\n",
    "cv.imshow('canny', canny)\n",
    "# 4. Dilating (l√†m d√†y) - m·ªü r·ªông v√πng tr·∫Øng\n",
    "dilate = cv.dilate(canny, (7,7), iterations= 3)\n",
    "cv.imshow('gian', dilate)\n",
    "# 5. Eroding (l√†m m·ªèng) - thu nh·ªè v√πng tr·∫Øng\n",
    "erode = cv.erode(canny, (7,7), iterations= 3)\n",
    "cv.imshow('mo', erode)\n",
    "# 6. Resize ·∫£nh v·ªÅ 500x500\n",
    "# Tham s·ªë: image, new size, interpolation method\n",
    "moi = cv.resize(img, (500, 500))\n",
    "cv.imshow('anh', moi)\n",
    "# 7. Cropping - c·∫Øt m·ªôt v√πng [y1:y2, x1:x2]\n",
    "crop = img[200:400, 300:500]\n",
    "cv.waitKey(0)\n",
    "print(\"Ho√†n th√†nh b√†i 3!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### B√†i 4: Ph√©p Bi·∫øn ƒê·ªïi H√¨nh H·ªçc (Transformations)\n",
    "\n",
    "**ƒê·ªÅ b√†i:**\n",
    "Th·ª±c hi·ªán c√°c ph√©p bi·∫øn ƒë·ªïi sau tr√™n ·∫£nh `Resources/Photos/park.jpg`:\n",
    "1. T·ªãnh ti·∫øn (translate) ·∫£nh sang tr√°i 100 pixels v√† xu·ªëng d∆∞·ªõi 100 pixels\n",
    "2. Xoay (rotate) ·∫£nh -45 ƒë·ªô quanh t√¢m\n",
    "3. Xoay ·∫£nh -90 ƒë·ªô\n",
    "4. L·∫≠t (flip) ·∫£nh theo c·∫£ hai tr·ª•c\n",
    "\n",
    "**M·ª•c ti√™u h·ªçc t·∫≠p:**\n",
    "- T·∫°o translation matrix v√† s·ª≠ d·ª•ng `cv.warpAffine()`\n",
    "- T·∫°o rotation matrix v·ªõi `cv.getRotationMatrix2D()`\n",
    "- S·ª≠ d·ª•ng `cv.flip()` ƒë·ªÉ l·∫≠t ·∫£nh\n",
    "- Hi·ªÉu v·ªÅ affine transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ho√†n th√†nh b√†i 4!\n"
     ]
    }
   ],
   "source": [
    "### CODE GI·∫¢I B√ÄI 4\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('Resources/Photos/park.jpg')\n",
    "cv.imshow('Original', img)\n",
    "height, width = img.shape[:2]\n",
    "# 1. TRANSLATION (T·ªãnh ti·∫øn)\n",
    "\n",
    "\n",
    "# T·ªãnh ti·∫øn sang tr√°i 100px, xu·ªëng 100px\n",
    "tx = -100\n",
    "ty = 100\n",
    "M = np.float32([[1, 0, tx],[0, 1, ty]])\n",
    "t_img = cv.warpAffine(img, M, (width, height))\n",
    "cv.imshow('translation', t_img)\n",
    "# H∆Ø·ªöNG D·∫™N TH√äM CHO C√ÅC B·∫†N\n",
    "# 2. ROTATION (Xoay)\n",
    "def rotate(img, angle, rotPoint=None):\n",
    "    \"\"\"\n",
    "    Xoay ·∫£nh quanh m·ªôt ƒëi·ªÉm\n",
    "    angle: g√≥c xoay (d∆∞∆°ng = ng∆∞·ª£c chi·ªÅu kim ƒë·ªìng h·ªì)\n",
    "    rotPoint: t√¢m xoay (m·∫∑c ƒë·ªãnh l√† t√¢m ·∫£nh)\n",
    "    \"\"\"\n",
    "    (height, width) = img.shape[:2]\n",
    "    \n",
    "    if rotPoint is None:\n",
    "        rotPoint = (width // 2, height // 2)\n",
    "    \n",
    "    # T·∫°o rotation matrix: (t√¢m, g√≥c, scale)\n",
    "    rotMat = cv.getRotationMatrix2D(rotPoint, angle, 1.0)\n",
    "    dimensions = (width, height)\n",
    "    \n",
    "    return cv.warpAffine(img, rotMat, dimensions)\n",
    "\n",
    "# Xoay -45 ƒë·ªô\n",
    "\n",
    "r45 = rotate(img, -45)\n",
    "cv.imshow('45', r45)\n",
    "# Xoay -90 ƒë·ªô\n",
    "r90 = rotate(img, -90)\n",
    "cv.imshow('90', r90)\n",
    "\n",
    "# 3. FLIPPING (L·∫≠t)\n",
    "# flipCode: 0 = l·∫≠t theo tr·ª•c x, 1 = l·∫≠t theo tr·ª•c y, -1 = l·∫≠t c·∫£ hai\n",
    "fimg = cv.flip(img, 1)\n",
    "cv.imshow('flip', fimg)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "print(\"Ho√†n th√†nh b√†i 4!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### B√†i 5: Ph√°t Hi·ªán Contours (ƒê∆∞·ªùng Vi·ªÅn)\n",
    "\n",
    "**ƒê·ªÅ b√†i:**\n",
    "1. ƒê·ªçc ·∫£nh `Resources/Photos/cats.jpg`\n",
    "2. Chuy·ªÉn sang grayscale v√† l√†m m·ªù\n",
    "3. Ph√°t hi·ªán c·∫°nh b·∫±ng Canny\n",
    "4. T√¨m t·∫•t c·∫£ contours trong ·∫£nh\n",
    "5. V·∫Ω c√°c contours l√™n m·ªôt canvas tr·∫Øng\n",
    "6. In ra s·ªë l∆∞·ª£ng contours t√¨m ƒë∆∞·ª£c\n",
    "\n",
    "**M·ª•c ti√™u h·ªçc t·∫≠p:**\n",
    "- S·ª≠ d·ª•ng `cv.findContours()` ƒë·ªÉ t√¨m ƒë∆∞·ªùng vi·ªÅn\n",
    "- Hi·ªÉu v·ªÅ retrieval modes v√† approximation methods\n",
    "- S·ª≠ d·ª•ng `cv.drawContours()` ƒë·ªÉ v·∫Ω contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T√¨m th·∫•y 380 contour(s)!\n",
      "Ho√†n th√†nh b√†i 5!\n"
     ]
    }
   ],
   "source": [
    "### CODE GI·∫¢I B√ÄI 5\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# ƒê·ªçc ·∫£nh\n",
    "img = cv.imread('Resources/Photos/cats.jpg')\n",
    "cv.imshow('Cats', img)\n",
    "\n",
    "# T·∫°o canvas tr·∫Øng c√≥ c√πng k√≠ch th∆∞·ªõc\n",
    "\n",
    "# Chuy·ªÉn sang grayscale\n",
    "\n",
    "# L√†m m·ªù ƒë·ªÉ gi·∫£m noise\n",
    "\n",
    "# Ph√°t hi·ªán c·∫°nh\n",
    "\n",
    "# GI·ªöI THI·ªÜU TH√äM CHO C√ÅC B·∫†N\n",
    "# T√¨m contours\n",
    "# cv.RETR_LIST: l·∫•y t·∫•t c·∫£ contours\n",
    "# cv.CHAIN_APPROX_SIMPLE: n√©n contours ƒë·ªÉ ti·∫øt ki·ªám b·ªô nh·ªõ\n",
    "contours, hierarchies = cv.findContours(canny, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "print(f'T√¨m th·∫•y {len(contours)} contour(s)!')\n",
    "\n",
    "# V·∫Ω contours\n",
    "# Tham s·ªë: image, contours list, contour index (-1 = all), color, thickness\n",
    "cv.drawContours(blank, contours, -1, (0, 0, 255), 1)\n",
    "cv.imshow('Contours Drawn', blank)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "print(\"Ho√†n th√†nh b√†i 5!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PH·∫¶N 2: N√ÇNG CAO (ADVANCED)\n",
    "\n",
    "### B√†i 6: Color Spaces (Kh√¥ng Gian M√†u) Anh th·∫•y c√°i n√†y ch∆∞a ƒë∆∞·ª£c gi·ªõi thi·ªáu tr√™n l·ªõp c√°c b·∫°n n√™n t√¨m hi·ªÉu th√™m v·ªÅ n√≥\n",
    "\n",
    "**ƒê·ªÅ b√†i:**\n",
    "Chuy·ªÉn ƒë·ªïi ·∫£nh `Resources/Photos/park.jpg` sang c√°c color spaces kh√°c nhau:\n",
    "1. BGR ‚Üí Grayscale\n",
    "2. BGR ‚Üí HSV\n",
    "3. BGR ‚Üí LAB\n",
    "4. BGR ‚Üí RGB\n",
    "5. LAB ‚Üí BGR (chuy·ªÉn ng∆∞·ª£c l·∫°i)\n",
    "\n",
    "**M·ª•c ti√™u h·ªçc t·∫≠p:**\n",
    "- Hi·ªÉu v·ªÅ c√°c color spaces kh√°c nhau\n",
    "- S·ª≠ d·ª•ng `cv.cvtColor()` v·ªõi c√°c conversion codes\n",
    "- Bi·∫øt khi n√†o n√™n d√πng color space n√†o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ho√†n th√†nh b√†i 6!\n",
      "\n",
      "Ghi ch√∫:\n",
      "- Grayscale: Gi·∫£m th√¥ng tin m√†u, t·ªët cho edge detection\n",
      "- HSV: T√°ch m√†u s·∫Øc kh·ªèi ƒë·ªô s√°ng, t·ªët cho color detection\n",
      "- LAB: Perception-based, t·ªët cho color comparison\n",
      "- RGB: Standard format cho h·∫ßu h·∫øt applications\n"
     ]
    }
   ],
   "source": [
    "#### GI·ªöI THI·ªÜU TH√äM CHO C√ÅC B·∫†N V·ªÄ CHUY·ªÇN ƒê·ªîI KH√îNG GIAN M√ÄU\n",
    "### CODE GI·∫¢I B√ÄI 6\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('Resources/Photos/park.jpg')\n",
    "cv.imshow('Original', img)\n",
    "\n",
    "# 1. BGR to Grayscale (x√°m)\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Grayscale', gray)\n",
    "\n",
    "# 2. BGR to HSV (Hue-Saturation-Value)\n",
    "# HSV t·ªët cho vi·ªác ph√°t hi·ªán m√†u s·∫Øc\n",
    "hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "cv.imshow('HSV', hsv)\n",
    "\n",
    "# 3. BGR to LAB (L*a*b)\n",
    "# LAB t·ªët cho color matching v√† comparison\n",
    "lab = cv.cvtColor(img, cv.COLOR_BGR2LAB)\n",
    "cv.imshow('LAB', lab)\n",
    "\n",
    "# 4. BGR to RGB\n",
    "# RGB d√πng cho matplotlib v√† c√°c th∆∞ vi·ªán kh√°c\n",
    "rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "cv.imshow('RGB', rgb)\n",
    "\n",
    "# 5. Chuy·ªÉn ng∆∞·ª£c: LAB to BGR\n",
    "lab_bgr = cv.cvtColor(lab, cv.COLOR_LAB2BGR)\n",
    "cv.imshow('LAB --> BGR', lab_bgr)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "print(\"Ho√†n th√†nh b√†i 6!\")\n",
    "print(\"\\nGhi ch√∫:\")\n",
    "print(\"- Grayscale: Gi·∫£m th√¥ng tin m√†u, t·ªët cho edge detection\")\n",
    "print(\"- HSV: T√°ch m√†u s·∫Øc kh·ªèi ƒë·ªô s√°ng, t·ªët cho color detection\")\n",
    "print(\"- LAB: Perception-based, t·ªët cho color comparison\")\n",
    "print(\"- RGB: Standard format cho h·∫ßu h·∫øt applications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### B√†i 7: Blurring (L√†m M·ªù)\n",
    "\n",
    "**ƒê·ªÅ b√†i:**\n",
    "√Åp d·ª•ng c√°c k·ªπ thu·∫≠t l√†m m·ªù kh√°c nhau l√™n ·∫£nh `Resources/Photos/cats.jpg`:\n",
    "1. Average Blur\n",
    "2. Gaussian Blur\n",
    "3. Median Blur\n",
    "4. Bilateral Filter\n",
    "\n",
    "So s√°nh k·∫øt qu·∫£ c·ªßa c√°c ph∆∞∆°ng ph√°p.\n",
    "\n",
    "**M·ª•c ti√™u h·ªçc t·∫≠p:**\n",
    "- Hi·ªÉu s·ª± kh√°c bi·ªát gi·ªØa c√°c k·ªπ thu·∫≠t blur\n",
    "- Bi·∫øt khi n√†o n√™n d√πng blur n√†o\n",
    "- S·ª≠ d·ª•ng `cv.blur()`, `cv.GaussianBlur()`, `cv.medianBlur()`, `cv.bilateralFilter()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ho√†n th√†nh b√†i 7!\n",
      "\n",
      "So s√°nh c√°c ph∆∞∆°ng ph√°p blur:\n",
      "- Average: Nhanh nh·∫•t, blur ƒë·ªìng ƒë·ªÅu\n",
      "- Gaussian: Blur t·ª± nhi√™n h∆°n, ∆∞u ti√™n pixels g·∫ßn t√¢m\n",
      "- Median: T·ªët cho noise, ƒë·∫∑c bi·ªát salt-and-pepper\n",
      "- Bilateral: Ch·∫≠m nh·∫•t nh∆∞ng gi·ªØ edge t·ªët nh·∫•t\n"
     ]
    }
   ],
   "source": [
    "### CODE GI·∫¢I B√ÄI 7\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('Resources/Photos/cats.jpg')\n",
    "cv.imshow('Original Cats', img)\n",
    "\n",
    "# 1. GAUSSIAN BLUR\n",
    "# S·ª≠ d·ª•ng Gaussian kernel - pixels g·∫ßn t√¢m c√≥ tr·ªçng s·ªë cao h∆°n\n",
    "# T·ªët h∆°n Average blur, gi·ªØ ƒë∆∞·ª£c edge t·ªët h∆°n\n",
    "gblur = cv.GaussianBlur(img, (7,7), cv.BORDER_DEFAULT)\n",
    "cv.imshow('gaussian blur', gblur)\n",
    "# Gi·ªöI THI·ªÜU TH√äM CHO C√ÅC B·∫†N 1 S·ªê K·ª∏ THU·∫¨T KH√ÅC ANH CH∆ØA TH·∫§Y GI·ªöI THI·ªÜU TR√äN L·ªöP\n",
    "# 2. AVERAGE BLUR\n",
    "# L·∫•y trung b√¨nh c·ªßa t·∫•t c·∫£ pixels trong kernel\n",
    "# ƒê∆°n gi·∫£n nh∆∞ng c√≥ th·ªÉ l√†m m·∫•t edge\n",
    "average = cv.blur(img, (3, 3))\n",
    "cv.imshow('Average Blur', average)\n",
    "\n",
    "# 3. MEDIAN BLUR\n",
    "# L·∫•y gi√° tr·ªã median thay v√¨ mean\n",
    "# R·∫•t hi·ªáu qu·∫£ v·ªõi salt-and-pepper noise\n",
    "median = cv.medianBlur(img, 3)\n",
    "cv.imshow('Median Blur', median)\n",
    "\n",
    "# 4. BILATERAL FILTER\n",
    "# L√†m m·ªù nh∆∞ng V·∫™N GI·ªÆ EDGE\n",
    "# Ch·∫≠m h∆°n nh∆∞ng k·∫øt qu·∫£ t·ªët nh·∫•t\n",
    "# Tham s·ªë: image, diameter, sigmaColor, sigmaSpace\n",
    "bilateral = cv.bilateralFilter(img, 10, 35, 25)\n",
    "cv.imshow('Bilateral Blur', bilateral)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "print(\"Ho√†n th√†nh b√†i 7!\")\n",
    "print(\"\\nSo s√°nh c√°c ph∆∞∆°ng ph√°p blur:\")\n",
    "print(\"- Average: Nhanh nh·∫•t, blur ƒë·ªìng ƒë·ªÅu\")\n",
    "print(\"- Gaussian: Blur t·ª± nhi√™n h∆°n, ∆∞u ti√™n pixels g·∫ßn t√¢m\")\n",
    "print(\"- Median: T·ªët cho noise, ƒë·∫∑c bi·ªát salt-and-pepper\")\n",
    "print(\"- Bilateral: Ch·∫≠m nh·∫•t nh∆∞ng gi·ªØ edge t·ªët nh·∫•t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## B√ÄI T·∫¨P T·ªîNG H·ª¢P\n",
    "\n",
    "### B√†i 8: B√†i T·∫≠p T·ªïng H·ª£p - X·ª≠ L√Ω ·∫¢nh Ho√†n Ch·ªânh\n",
    "\n",
    "**ƒê·ªÅ b√†i:**\n",
    "T·∫°o m·ªôt ch∆∞∆°ng tr√¨nh x·ª≠ l√Ω ·∫£nh ho√†n ch·ªânh v·ªõi c√°c b∆∞·ªõc sau:\n",
    "\n",
    "1. ƒê·ªçc ·∫£nh `Resources/Photos/park.jpg`\n",
    "2. Resize ·∫£nh v·ªÅ 600x600 pixels\n",
    "3. Chuy·ªÉn sang HSV v√† t√°ch c√°c channels\n",
    "4. √Åp d·ª•ng Gaussian Blur v·ªõi kernel 5x5\n",
    "5. Ph√°t hi·ªán c·∫°nh b·∫±ng Canny\n",
    "6. T√¨m v√† v·∫Ω t·∫•t c·∫£ contours l√™n ·∫£nh g·ªëc\n",
    "7. Th√™m text th√¥ng tin: s·ªë contours t√¨m ƒë∆∞·ª£c\n",
    "8. L∆∞u k·∫øt qu·∫£ ra file\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "- K·∫øt h·ª£p nhi·ªÅu k·ªπ thu·∫≠t ƒë√£ h·ªçc\n",
    "- T·∫°o pipeline x·ª≠ l√Ω ·∫£nh ho√†n ch·ªânh\n",
    "- L∆∞u k·∫øt qu·∫£ ra file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë contours t√¨m ƒë∆∞·ª£c: 42\n",
      "ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: processed_park.jpg\n",
      "\n",
      "==================================================\n",
      "HO√ÄN TH√ÄNH B√ÄI T·∫¨P T·ªîNG H·ª¢P!\n",
      "==================================================\n",
      "T·ªïng s·ªë contours ph√°t hi·ªán: 42\n",
      "K√≠ch th∆∞·ªõc ·∫£nh x·ª≠ l√Ω: (600, 600, 3)\n",
      "File k·∫øt qu·∫£: processed_park.jpg\n"
     ]
    }
   ],
   "source": [
    "### CODE GI·∫¢I B√ÄI 8 - T·ªîNG H·ª¢P\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# B∆∞·ªõc 1: ƒê·ªçc ·∫£nh\n",
    "img = cv.imread('Resources/Photos/park.jpg')\n",
    "cv.imshow('orignal', img)\n",
    "# B∆∞·ªõc 2: Resize\n",
    "resized = cv.resize(img, (600, 600))\n",
    "cv.imshow('resize', resized)\n",
    "# B∆∞·ªõc 3: Chuy·ªÉn sang HSV\n",
    "hsv = cv.cvtColor(resized, cv.COLOR_BGR2HSV)\n",
    "cv.imshow('2. HSV', hsv)\n",
    "\n",
    "# T√°ch channels HSV\n",
    "h, s, v = cv.split(hsv)\n",
    "cv.imshow('Hue Channel', h)\n",
    "cv.imshow('Saturation Channel', s)\n",
    "cv.imshow('Value Channel', v)\n",
    "\n",
    "# B∆∞·ªõc 4: Gaussian Blur tr√™n ·∫£nh g·ªëc ƒë√£ resize\n",
    "blured = cv.GaussianBlur(resized, (7,7), cv.BORDER_DEFAULT )\n",
    "\n",
    "# B∆∞·ªõc 5: Chuy·ªÉn sang grayscale v√† Canny Edge Detection\n",
    "grayed = cv.cvtColor(blured, cv.COLOR_BGR2GRAY)\n",
    "canny = cv.Canny(grayed, 120, 170)\n",
    "# B∆∞·ªõc 6: T√¨m contours\n",
    "contours, hierarchies = cv.findContours(canny, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "num_contours = len(contours)\n",
    "print(f\"S·ªë contours t√¨m ƒë∆∞·ª£c: {num_contours}\")\n",
    "\n",
    "# V·∫Ω contours l√™n ·∫£nh g·ªëc (t·∫°o b·∫£n copy)\n",
    "result = resized.copy()\n",
    "cv.drawContours(result, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# B∆∞·ªõc 7: Th√™m text th√¥ng tin\n",
    "text = f'Contours: {num_contours}'\n",
    "cv.putText(result, text, (10, 30), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "# Th√™m watermark\n",
    "cv.putText(result, 'OpenCV Project', (10, result.shape[0] - 10), \n",
    "           cv.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "cv.imshow('5. Final Result', result)\n",
    "\n",
    "# B∆∞·ªõc 8: L∆∞u k·∫øt qu·∫£\n",
    "output_path = 'processed_park.jpg'\n",
    "cv.imwrite(output_path, result)\n",
    "print(f\"ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: {output_path}\")\n",
    "\n",
    "# T·∫°o m·ªôt composite image ƒë·ªÉ so s√°nh\n",
    "# Stack ·∫£nh g·ªëc v√† k·∫øt qu·∫£ c·∫°nh nhau\n",
    "comparison = np.hstack([resized, result])\n",
    "cv.imshow('6. Comparison: Original vs Processed', comparison)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"HO√ÄN TH√ÄNH B√ÄI T·∫¨P T·ªîNG H·ª¢P!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"T·ªïng s·ªë contours ph√°t hi·ªán: {num_contours}\")\n",
    "print(f\"K√≠ch th∆∞·ªõc ·∫£nh x·ª≠ l√Ω: {result.shape}\")\n",
    "print(f\"File k·∫øt qu·∫£: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## B√ÄI T·∫¨P TH·ª∞C H√ÄNH TH√äM\n",
    "## ƒê√¢y l√† anh t·ª± nghƒ© v√† t·ª± t√¨m hi·ªÉu ƒë·ªÉ l√†m nƒÉm ngo√°i, c√°c b·∫°n c√≥ th·ªÉ t·ª± s√°ng t·∫°o v√† t√¨m hi·ªÉu n·∫øu ch∆∞a c√°c ki·∫øn th·ª©c ƒë∆∞·ª£c cung c·∫•p\n",
    "\n",
    "### B√†i 9: Th·ª≠ Th√°ch - C√°c b·∫°n c√≥ th·ªÉ t·ª± s√°ng theo √Ω m√¨nh\n",
    "\n",
    "**Y√™u c·∫ßu:**\n",
    "1. ƒê·ªçc m·ªôt ·∫£nh b·∫•t k·ª≥ t·ª´ th∆∞ m·ª•c Resources\n",
    "2. T·∫°o m·ªôt creative effect b·∫±ng c√°ch k·∫øt h·ª£p:\n",
    "   - √çt nh·∫•t 3 color space transformations\n",
    "   - 2 lo·∫°i blur kh√°c nhau\n",
    "   - Masking v·ªõi shape t·ª± t·∫°o\n",
    "   - Text v√† drawing\n",
    "3. L∆∞u l·∫°i k·∫øt qu·∫£ v√† gi·∫£i th√≠ch t·ª´ng b∆∞·ªõc\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "- S√°ng t·∫°o v√† √°p d·ª•ng ki·∫øn th·ª©c ƒë√£ h·ªçc\n",
    "- Hi·ªÉu s√¢u v·ªÅ c√°ch c√°c k·ªπ thu·∫≠t k·∫øt h·ª£p v·ªõi nhau\n",
    "\n",
    "**G·ª£i √Ω:**\n",
    "- Th·ª≠ t·∫°o Instagram-like filters\n",
    "- T·∫°o vignette effect\n",
    "- T·∫°o artistic blur effects\n",
    "- Highlight m·ªôt v√πng c·ª• th·ªÉ c·ªßa ·∫£nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "B√ÄI 9: T·∫†O CREATIVE EFFECT - VIGNETTE & ARTISTIC FILTER\n",
      "============================================================\n",
      "\n",
      "[1] Chuy·ªÉn ƒë·ªïi Color Spaces...\n",
      "[2] √Åp d·ª•ng Artistic Blur...\n",
      "[3] T·∫°o Vignette Effect...\n",
      "[4] T·∫°o Center Highlight v·ªõi Masking...\n",
      "[5] Th√™m Text v√† Decorations...\n",
      "\n",
      "‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£: bai10_creative_result.jpg\n",
      "\n",
      "============================================================\n",
      "HO√ÄN TH√ÄNH B√ÄI 9!\n",
      "============================================================\n",
      "\n",
      "K·ªπ thu·∫≠t ƒë√£ s·ª≠ d·ª•ng:\n",
      "‚úì 3 Color Spaces: LAB, HSV, BGR\n",
      "‚úì 2 Blur Methods: Bilateral + Gaussian\n",
      "‚úì Vignette Effect v·ªõi Gaussian Kernel\n",
      "‚úì Circular Masking v·ªõi Gradient\n",
      "‚úì Text, Shapes v√† Decorations\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"B√ÄI 9: T·∫†O CREATIVE EFFECT - VIGNETTE & ARTISTIC FILTER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ƒê·ªçc ·∫£nh\n",
    "img = cv.imread('Resources/Photos/park.jpg')\n",
    "cv.imshow('Original', img)\n",
    "\n",
    "# Resize v·ªÅ k√≠ch th∆∞·ªõc chu·∫©n\n",
    "img = cv.resize(img, (600, 600), interpolation=cv.INTER_AREA)\n",
    "\n",
    "# B∆Ø·ªöC 1: Color Space Transformations\n",
    "print(\"\\n[1] Chuy·ªÉn ƒë·ªïi Color Spaces...\")\n",
    "\n",
    "# Chuy·ªÉn sang LAB ƒë·ªÉ ƒëi·ªÅu ch·ªânh brightness\n",
    "lab = cv.cvtColor(img, cv.COLOR_BGR2LAB)\n",
    "l, a, b = cv.split(lab)\n",
    "\n",
    "# TƒÉng ƒë·ªô s√°ng m·ªôt ch√∫t\n",
    "l = cv.add(l, 20)\n",
    "enhanced_lab = cv.merge([l, a, b])\n",
    "enhanced = cv.cvtColor(enhanced_lab, cv.COLOR_LAB2BGR)\n",
    "\n",
    "# Chuy·ªÉn sang HSV ƒë·ªÉ tƒÉng saturation\n",
    "hsv = cv.cvtColor(enhanced, cv.COLOR_BGR2HSV)\n",
    "h, s, v = cv.split(hsv)\n",
    "s = cv.add(s, 30)  # TƒÉng saturation\n",
    "vibrant_hsv = cv.merge([h, s, v])\n",
    "vibrant = cv.cvtColor(vibrant_hsv, cv.COLOR_HSV2BGR)\n",
    "\n",
    "cv.imshow('1. Enhanced Colors', vibrant)\n",
    "\n",
    "# B∆Ø·ªöC 2: Artistic Blur Effects\n",
    "print(\"[2] √Åp d·ª•ng Artistic Blur...\")\n",
    "\n",
    "# Bilateral filter ƒë·ªÉ gi·ªØ edge nh∆∞ng smooth v√πng ph·∫≥ng\n",
    "artistic = cv.bilateralFilter(vibrant, 15, 80, 80)\n",
    "\n",
    "# Th√™m m·ªôt ch√∫t Gaussian blur nh·∫π\n",
    "artistic = cv.GaussianBlur(artistic, (3, 3), 0)\n",
    "\n",
    "cv.imshow('2. Artistic Blur', artistic)\n",
    "\n",
    "# B∆Ø·ªöC 3: T·∫°o Vignette Effect\n",
    "print(\"[3] T·∫°o Vignette Effect...\")\n",
    "\n",
    "# T·∫°o gradient mask t·ª´ t√¢m ra ngo√†i\n",
    "rows, cols = artistic.shape[:2]\n",
    "kernel_x = cv.getGaussianKernel(cols, cols/2)\n",
    "kernel_y = cv.getGaussianKernel(rows, rows/2)\n",
    "kernel = kernel_y * kernel_x.T\n",
    "vignette_mask = kernel / kernel.max()\n",
    "\n",
    "# √Åp d·ª•ng vignette mask\n",
    "vignette = artistic.copy()\n",
    "for i in range(3):  # √Åp d·ª•ng cho c·∫£ 3 channels BGR\n",
    "    vignette[:, :, i] = vignette[:, :, i] * vignette_mask\n",
    "\n",
    "cv.imshow('3. Vignette Effect', vignette)\n",
    "\n",
    "# B∆Ø·ªöC 4: Shape Masking - Highlight Center\n",
    "print(\"[4] T·∫°o Center Highlight v·ªõi Masking...\")\n",
    "\n",
    "# T·∫°o circular mask ·ªü gi·ªØa\n",
    "blank_mask = np.zeros((rows, cols), dtype='uint8')\n",
    "center = (cols // 2, rows // 2)\n",
    "radius = min(rows, cols) // 3\n",
    "\n",
    "# V·∫Ω circle mask v·ªõi gradient\n",
    "cv.circle(blank_mask, center, radius, 255, -1)\n",
    "blur_mask = cv.GaussianBlur(blank_mask, (101, 101), 0)\n",
    "\n",
    "# T·∫°o highlighted version\n",
    "highlighted = artistic.copy()\n",
    "for i in range(3):\n",
    "    highlighted[:, :, i] = cv.addWeighted(\n",
    "        artistic[:, :, i], 0.5,\n",
    "        vignette[:, :, i], 0.5,\n",
    "        0\n",
    "    )\n",
    "\n",
    "# Blend original v√† highlighted d·ª±a tr√™n mask\n",
    "result = vignette.copy()\n",
    "for i in range(3):\n",
    "    result[:, :, i] = np.where(\n",
    "        blur_mask > 128,\n",
    "        artistic[:, :, i],\n",
    "        vignette[:, :, i]\n",
    "    )\n",
    "\n",
    "cv.imshow('4. Center Highlighted', result)\n",
    "\n",
    "# B∆Ø·ªöC 5: Th√™m Text v√† Drawing\n",
    "print(\"[5] Th√™m Text v√† Decorations...\")\n",
    "\n",
    "final_result = result.copy()\n",
    "\n",
    "# V·∫Ω khung vi·ªÅn\n",
    "cv.rectangle(final_result, (10, 10), (590, 590), (255, 255, 255), 3)\n",
    "\n",
    "# Th√™m title\n",
    "cv.putText(final_result, 'ARTISTIC VIGNETTE', (20, 50),\n",
    "           cv.FONT_HERSHEY_DUPLEX, 1.2, (255, 255, 255), 2)\n",
    "\n",
    "# Th√™m subtitle\n",
    "cv.putText(final_result, 'Creative OpenCV Filter', (20, 80),\n",
    "           cv.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 1)\n",
    "\n",
    "# Th√™m watermark ·ªü g√≥c\n",
    "cv.putText(final_result, 'OpenCV 2025', (420, 580),\n",
    "           cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "# V·∫Ω m·ªôt v√†i decorative circles\n",
    "cv.circle(final_result, (50, 550), 15, (255, 200, 0), 2)\n",
    "cv.circle(final_result, (550, 50), 15, (0, 200, 255), 2)\n",
    "\n",
    "cv.imshow('5. FINAL RESULT - B√ÄI 10', final_result)\n",
    "\n",
    "# L∆∞u k·∫øt qu·∫£\n",
    "output_file = 'bai10_creative_result.jpg'\n",
    "cv.imwrite(output_file, final_result)\n",
    "print(f\"\\n‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£: {output_file}\")\n",
    "\n",
    "# So s√°nh before/after\n",
    "comparison = np.hstack([\n",
    "    cv.resize(img, (300, 300)),\n",
    "    cv.resize(final_result, (300, 300))\n",
    "])\n",
    "cv.imshow('6. Before vs After', comparison)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"HO√ÄN TH√ÄNH B√ÄI 9!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nK·ªπ thu·∫≠t ƒë√£ s·ª≠ d·ª•ng:\")\n",
    "print(\"‚úì 3 Color Spaces: LAB, HSV, BGR\")\n",
    "print(\"‚úì 2 Blur Methods: Bilateral + Gaussian\")\n",
    "print(\"‚úì Vignette Effect v·ªõi Gaussian Kernel\")\n",
    "print(\"‚úì Circular Masking v·ªõi Gradient\")\n",
    "print(\"‚úì Text, Shapes v√† Decorations\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B√†i 10: X·ª≠ L√Ω Video - Extract & Process Frames\n",
    "\n",
    "### ƒê·ªÅ b√†i:\n",
    "\n",
    "L√†m vi·ªác v·ªõi video ƒë·ªÉ tr√≠ch xu·∫•t frames v√† x·ª≠ l√Ω t·ª´ng frame m·ªôt:\n",
    "\n",
    "**Y√™u c·∫ßu:**\n",
    "\n",
    "**Ph·∫ßn 1: ƒê·ªçc v√† ph√¢n t√≠ch video**\n",
    "1. ƒê·ªçc video t·ª´ `Resources/Videos/dog.mp4`\n",
    "2. L·∫•y v√† hi·ªÉn th·ªã th√¥ng tin video:\n",
    "   - FPS (frames per second)\n",
    "   - T·ªïng s·ªë frames\n",
    "   - K√≠ch th∆∞·ªõc (width x height) \n",
    "   - Th·ªùi l∆∞·ª£ng (duration)\n",
    "\n",
    "**Ph·∫ßn 2: Tr√≠ch xu·∫•t frames**\n",
    "3. Tr√≠ch xu·∫•t 5-10 frames t·ª´ video\n",
    "4. L∆∞u c√°c frames v√†o th∆∞ m·ª•c `extracted_frames/`\n",
    "5. ƒê·∫∑t t√™n file theo format: `frame_0000.jpg`, `frame_0001.jpg`, ...\n",
    "\n",
    "**Ph·∫ßn 3: X·ª≠ l√Ω c√°c frames ƒë√£ tr√≠ch xu·∫•t**\n",
    "6. ƒê·ªçc l·∫°i c√°c frames ƒë√£ l∆∞u\n",
    "7. √Åp d·ª•ng **4 k·ªπ thu·∫≠t x·ª≠ l√Ω** l√™n m·ªói frame:\n",
    "   - **Grayscale**: Chuy·ªÉn sang ·∫£nh x√°m\n",
    "   - **Edge Detection**: Ph√°t hi·ªán c·∫°nh v·ªõi Canny\n",
    "   - **Cartoon Effect**: K·∫øt h·ª£p bilateral filter + adaptive threshold\n",
    "   - **Brightness**: TƒÉng ƒë·ªô s√°ng qua HSV\n",
    "8. T·∫°o composite image v·ªõi 4 views (2x2 grid):\n",
    "   - Top-left: Original\n",
    "   - Top-right: Grayscale\n",
    "   - Bottom-left: Edges\n",
    "   - Bottom-right: Cartoon\n",
    "9. Th√™m labels cho m·ªói view\n",
    "10. L∆∞u c√°c composite images v√†o th∆∞ m·ª•c `processed_frames/`\n",
    "\n",
    "**Ph·∫ßn 4: Hi·ªÉn th·ªã video v·ªõi effects**\n",
    "11. ƒê·ªçc l·∫°i video t·ª´ ƒë·∫ßu\n",
    "12. Hi·ªÉn th·ªã video v·ªõi real-time cartoon effect\n",
    "13. So s√°nh Original vs Processed c·∫°nh nhau\n",
    "14. Cho ph√©p nh·∫•n 'd' ƒë·ªÉ d·ª´ng\n",
    "\n",
    "**M·ª•c ti√™u h·ªçc t·∫≠p:**\n",
    "- ƒê·ªçc v√† ph√¢n t√≠ch video v·ªõi `cv.VideoCapture()`\n",
    "- Tr√≠ch xu·∫•t frames t·ª´ video\n",
    "- X·ª≠ l√Ω batch nhi·ªÅu frames\n",
    "- T·∫°o cartoon effect\n",
    "- Hi·ªÉn th·ªã video real-time\n",
    "- T·∫°o composite multi-view images\n",
    "\n",
    "**Ki·∫øn th·ª©c c·∫ßn d√πng:**\n",
    "- `cv.VideoCapture()` - ƒê·ªçc video\n",
    "- `cap.get(cv.CAP_PROP_FPS)` - L·∫•y FPS\n",
    "- `cap.get(cv.CAP_PROP_FRAME_COUNT)` - L·∫•y t·ªïng frames\n",
    "- `cap. read()` - ƒê·ªçc frame\n",
    "- `cv.bilateralFilter()` - Smooth nh∆∞ng gi·ªØ edge\n",
    "- `cv.adaptiveThreshold()` - Threshold ƒë·ªông\n",
    "- `np.hstack()`, `np.vstack()` - Stack images\n",
    "\n",
    "**Cartoon Effect Algorithm:**\n",
    "```\n",
    "1. Apply bilateral filter (smooth but keep edges)\n",
    "2. Convert to grayscale\n",
    "3. Apply median blur\n",
    "4. Apply adaptive threshold to get edges\n",
    "5. Combine blurred color v·ªõi edge mask\n",
    "```\n",
    "\n",
    "**Tips:**\n",
    "- ƒê·ªÉ extract ƒë·ªÅu, l·∫•y 1 frame m·ªói gi√¢y: `if frame_count % fps == 0`\n",
    "- Adaptive threshold parameters: blockSize=9, C=2\n",
    "- Bilateral filter cho cartoon: diameter=9, sigma=75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "B√ÄI 10: X·ª¨ L√ù VIDEO - EXTRACT & PROCESS FRAMES\n",
      "============================================================\n",
      "\n",
      "üìπ Th√¥ng tin video:\n",
      "   - FPS: 29\n",
      "   - T·ªïng s·ªë frames: 336\n",
      "   - K√≠ch th∆∞·ªõc: 1280x720\n",
      "   - Th·ªùi l∆∞·ª£ng: 11.59 gi√¢y\n",
      "\n",
      "[1] Tr√≠ch xu·∫•t frames m·ªói 29 frame (1 frame/gi√¢y)...\n",
      "   ‚úì ƒê√£ l∆∞u: extracted_frames/frame_0000.jpg\n",
      "   ‚úì ƒê√£ l∆∞u: extracted_frames/frame_0001.jpg\n",
      "   ‚úì ƒê√£ l∆∞u: extracted_frames/frame_0002.jpg\n",
      "   ‚úì ƒê√£ l∆∞u: extracted_frames/frame_0003.jpg\n",
      "   ‚úì ƒê√£ l∆∞u: extracted_frames/frame_0004.jpg\n",
      "   ‚úì ƒê√£ l∆∞u: extracted_frames/frame_0005.jpg\n",
      "   ‚úì ƒê√£ l∆∞u: extracted_frames/frame_0006.jpg\n",
      "   ‚úì ƒê√£ l∆∞u: extracted_frames/frame_0007.jpg\n",
      "   ‚úì ƒê√£ l∆∞u: extracted_frames/frame_0008.jpg\n",
      "   ‚úì ƒê√£ l∆∞u: extracted_frames/frame_0009.jpg\n",
      "   ‚úì ƒê√£ l∆∞u: extracted_frames/frame_0010.jpg\n",
      "   ‚úì ƒê√£ l∆∞u: extracted_frames/frame_0011.jpg\n",
      "\n",
      "‚úÖ ƒê√£ tr√≠ch xu·∫•t 12 frames v√†o th∆∞ m·ª•c 'extracted_frames/'\n",
      "\n",
      "[2] X·ª≠ l√Ω video real-time v·ªõi c√°c hi·ªáu ·ª©ng...\n",
      "   Nh·∫•n 'd' ƒë·ªÉ tho√°t, 'p' ƒë·ªÉ pause/resume\n",
      "   Processing: 8.6% (29/336 frames)\n",
      "   Processing: 17.3% (58/336 frames)\n",
      "   Processing: 25.9% (87/336 frames)\n",
      "   Processing: 34.5% (116/336 frames)\n",
      "   Processing: 43.2% (145/336 frames)\n",
      "   Processing: 51.8% (174/336 frames)\n",
      "   Processing: 60.4% (203/336 frames)\n",
      "   Processing: 69.0% (232/336 frames)\n",
      "\n",
      "‚èπ D·ª´ng x·ª≠ l√Ω video\n",
      "\n",
      "‚úÖ ƒê√£ l∆∞u video ƒë√£ x·ª≠ l√Ω: processed_video.avi\n",
      "\n",
      "üìä Th·ªëng k√™:\n",
      "   - Frames ƒë√£ tr√≠ch xu·∫•t: 12 files\n",
      "   - Frames ƒë√£ x·ª≠ l√Ω: 241 frames\n",
      "   - Th∆∞ m·ª•c frames: extracted_frames/\n",
      "   - Video output: processed_video.avi\n",
      "\n",
      "============================================================\n",
      "HO√ÄN TH√ÄNH B√ÄI 10!\n",
      "============================================================\n",
      "\n",
      "ƒê√£ h·ªçc:\n",
      "‚úì ƒê·ªçc video v·ªõi VideoCapture\n",
      "‚úì L·∫•y th√¥ng tin video (FPS, frames, k√≠ch th∆∞·ªõc)\n",
      "‚úì Extract frames ƒë·ªãnh k·ª≥ v√† l∆∞u file\n",
      "‚úì X·ª≠ l√Ω video real-time v·ªõi nhi·ªÅu hi·ªáu ·ª©ng\n",
      "‚úì T·∫°o composite view (4 views c√πng l√∫c)\n",
      "‚úì Ghi video ƒë√£ x·ª≠ l√Ω v·ªõi VideoWriter\n",
      "‚úì Pause/Resume video processing\n",
      "============================================================\n",
      "\n",
      "üí° TH·ª∞C H√ÄNH:\n",
      "   1. M·ªü th∆∞ m·ª•c 'extracted_frames/' ƒë·ªÉ xem c√°c frames ƒë√£ tr√≠ch xu·∫•t\n",
      "   2. M·ªü file 'processed_video.avi' ƒë·ªÉ xem video cartoon effect\n",
      "   3. Th·ª≠ thay ƒë·ªïi c√°c tham s·ªë blur, edge detection\n",
      "   4. Th·ª≠ th√™m c√°c hi·ªáu ·ª©ng kh√°c (color filters, etc.)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# B√ÄI 10: X·ª¨ L√ù VIDEO - EXTRACT & PROCESS FRAMES\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"=\" * 60)\n",
    "print(\"B√ÄI 10: X·ª¨ L√ù VIDEO - EXTRACT & PROCESS FRAMES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ƒê·ªçc video\n",
    "video_path = 'Resources/Videos/dog.mp4'\n",
    "cap = cv.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"‚ùå Kh√¥ng th·ªÉ m·ªü video!\")\n",
    "    exit()\n",
    "\n",
    "# L·∫•y th√¥ng tin video\n",
    "fps = int(cap.get(cv.CAP_PROP_FPS))\n",
    "total_frames = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "print(f\"\\nüìπ Th√¥ng tin video:\")\n",
    "print(f\"   - FPS: {fps}\")\n",
    "print(f\"   - T·ªïng s·ªë frames: {total_frames}\")\n",
    "print(f\"   - K√≠ch th∆∞·ªõc: {width}x{height}\")\n",
    "print(f\"   - Th·ªùi l∆∞·ª£ng: {total_frames/fps:.2f} gi√¢y\")\n",
    "\n",
    "# PH·∫¶N 1: Extract frames ƒë·ªãnh k·ª≥\n",
    "print(f\"\\n[1] Tr√≠ch xu·∫•t frames m·ªói {fps} frame (1 frame/gi√¢y)...\")\n",
    "\n",
    "import os\n",
    "output_dir = 'extracted_frames'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "frame_count = 0\n",
    "extracted_count = 0\n",
    "extract_interval = fps  # L·∫•y 1 frame m·ªói gi√¢y\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Extract frame ƒë·ªãnh k·ª≥\n",
    "    if frame_count % extract_interval == 0:\n",
    "        filename = f'{output_dir}/frame_{extracted_count:04d}.jpg'\n",
    "        cv.imwrite(filename, frame)\n",
    "        extracted_count += 1\n",
    "        print(f\"   ‚úì ƒê√£ l∆∞u: {filename}\")\n",
    "    \n",
    "    frame_count += 1\n",
    "\n",
    "print(f\"\\n‚úÖ ƒê√£ tr√≠ch xu·∫•t {extracted_count} frames v√†o th∆∞ m·ª•c '{output_dir}/'\")\n",
    "\n",
    "# Reset video v·ªÅ ƒë·∫ßu\n",
    "cap.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "# PH·∫¶N 2: X·ª≠ l√Ω video real-time\n",
    "print(f\"\\n[2] X·ª≠ l√Ω video real-time v·ªõi c√°c hi·ªáu ·ª©ng...\")\n",
    "print(\"   Nh·∫•n 'd' ƒë·ªÉ tho√°t, 'p' ƒë·ªÉ pause/resume\")\n",
    "\n",
    "# T·∫°o video writer ƒë·ªÉ l∆∞u k·∫øt qu·∫£\n",
    "output_video = 'processed_video.avi'\n",
    "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "out = cv.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "frame_num = 0\n",
    "paused = False\n",
    "\n",
    "while True:\n",
    "    if not paused:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # === X·ª¨ L√ù FRAME ===\n",
    "        \n",
    "        # 1. Chuy·ªÉn sang grayscale\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        gray_bgr = cv.cvtColor(gray, cv.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # 2. Edge detection\n",
    "        edges = cv.Canny(gray, 50, 150)\n",
    "        edges_bgr = cv.cvtColor(edges, cv.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # 3. Cartoon effect\n",
    "        # Bilateral filter + edge detection\n",
    "        cartoon = cv.bilateralFilter(frame, 9, 75, 75)\n",
    "        cartoon_gray = cv.cvtColor(cartoon, cv.COLOR_BGR2GRAY)\n",
    "        cartoon_blur = cv.medianBlur(cartoon_gray, 7)\n",
    "        cartoon_edges = cv.adaptiveThreshold(\n",
    "            cartoon_blur, 255,\n",
    "            cv.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv.THRESH_BINARY, 9, 2\n",
    "        )\n",
    "        cartoon_edges_bgr = cv.cvtColor(cartoon_edges, cv.COLOR_GRAY2BGR)\n",
    "        cartoon_final = cv.bitwise_and(cartoon, cartoon_edges_bgr)\n",
    "        \n",
    "        # 4. Color modification (HSV)\n",
    "        hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "        h, s, v = cv.split(hsv)\n",
    "        s = cv.add(s, 50)  # TƒÉng saturation\n",
    "        vibrant_hsv = cv.merge([h, s, v])\n",
    "        vibrant_frame = cv.cvtColor(vibrant_hsv, cv.COLOR_HSV2BGR)\n",
    "        \n",
    "        # === T·∫†O COMPOSITE ===\n",
    "        \n",
    "        # Resize c√°c frame ƒë·ªÉ hi·ªÉn th·ªã 4 c√πng l√∫c\n",
    "        h_half, w_half = height // 2, width // 2\n",
    "        \n",
    "        original_small = cv.resize(frame, (w_half, h_half))\n",
    "        gray_small = cv.resize(gray_bgr, (w_half, h_half))\n",
    "        edges_small = cv.resize(edges_bgr, (w_half, h_half))\n",
    "        cartoon_small = cv.resize(cartoon_final, (w_half, h_half))\n",
    "        \n",
    "        # Th√™m labels\n",
    "        cv.putText(original_small, 'Original', (10, 30),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv.putText(gray_small, 'Grayscale', (10, 30),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv.putText(edges_small, 'Edges', (10, 30),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "        cv.putText(cartoon_small, 'Cartoon', (10, 30),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)\n",
    "        \n",
    "        # Stack frames\n",
    "        top_row = np.hstack([original_small, gray_small])\n",
    "        bottom_row = np.hstack([edges_small, cartoon_small])\n",
    "        composite = np.vstack([top_row, bottom_row])\n",
    "        \n",
    "        # Hi·ªÉn th·ªã\n",
    "        cv.imshow('Video Processing - 4 Views', composite)\n",
    "        \n",
    "        # L∆∞u frame ƒë√£ x·ª≠ l√Ω (cartoon effect) v√†o output video\n",
    "        out.write(cartoon_final)\n",
    "        \n",
    "        frame_num += 1\n",
    "        \n",
    "        # Hi·ªÉn th·ªã progress\n",
    "        if frame_num % fps == 0:\n",
    "            progress = (frame_num / total_frames) * 100\n",
    "            print(f\"   Processing: {progress:.1f}% ({frame_num}/{total_frames} frames)\")\n",
    "    \n",
    "    # X·ª≠ l√Ω keyboard input\n",
    "    key = cv.waitKey(20) & 0xFF\n",
    "    if key == ord('d'):\n",
    "        print(\"\\n‚èπ D·ª´ng x·ª≠ l√Ω video\")\n",
    "        break\n",
    "    elif key == ord('p'):\n",
    "        paused = not paused\n",
    "        status = \"PAUSED\" if paused else \"RESUMED\"\n",
    "        print(f\"   ‚è∏ {status}\")\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "out.release()\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "print(f\"\\n‚úÖ ƒê√£ l∆∞u video ƒë√£ x·ª≠ l√Ω: {output_video}\")\n",
    "\n",
    "# Th·ªëng k√™ frames ƒë√£ l∆∞u\n",
    "frame_files = [f for f in os.listdir(output_dir) if f.endswith('.jpg')]\n",
    "print(f\"\\nüìä Th·ªëng k√™:\")\n",
    "print(f\"   - Frames ƒë√£ tr√≠ch xu·∫•t: {len(frame_files)} files\")\n",
    "print(f\"   - Frames ƒë√£ x·ª≠ l√Ω: {frame_num} frames\")\n",
    "print(f\"   - Th∆∞ m·ª•c frames: {output_dir}/\")\n",
    "print(f\"   - Video output: {output_video}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"HO√ÄN TH√ÄNH B√ÄI 10!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nƒê√£ h·ªçc:\")\n",
    "print(\"‚úì ƒê·ªçc video v·ªõi VideoCapture\")\n",
    "print(\"‚úì L·∫•y th√¥ng tin video (FPS, frames, k√≠ch th∆∞·ªõc)\")\n",
    "print(\"‚úì Extract frames ƒë·ªãnh k·ª≥ v√† l∆∞u file\")\n",
    "print(\"‚úì X·ª≠ l√Ω video real-time v·ªõi nhi·ªÅu hi·ªáu ·ª©ng\")\n",
    "print(\"‚úì T·∫°o composite view (4 views c√πng l√∫c)\")\n",
    "print(\"‚úì Ghi video ƒë√£ x·ª≠ l√Ω v·ªõi VideoWriter\")\n",
    "print(\"‚úì Pause/Resume video processing\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüí° TH·ª∞C H√ÄNH:\")\n",
    "print(f\"   1. M·ªü th∆∞ m·ª•c '{output_dir}/' ƒë·ªÉ xem c√°c frames ƒë√£ tr√≠ch xu·∫•t\")\n",
    "print(f\"   2. M·ªü file '{output_video}' ƒë·ªÉ xem video cartoon effect\")\n",
    "print(f\"   3. Th·ª≠ thay ƒë·ªïi c√°c tham s·ªë blur, edge detection\")\n",
    "print(f\"   4. Th·ª≠ th√™m c√°c hi·ªáu ·ª©ng kh√°c (color filters, etc.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## T√ÄI LI·ªÜU THAM KH·∫¢O\n",
    "\n",
    "### OpenCV Documentation\n",
    "- [Official OpenCV Documentation](https://docs.opencv.org/)\n",
    "- [OpenCV Python Tutorials](https://docs.opencv.org/master/d6/d00/tutorial_py_root.html)\n",
    "\n",
    "### Video Tutorial\n",
    "- [freeCodeCamp OpenCV Course](https://youtu.be/oXlwWbU8l2o)\n",
    "\n",
    "### M·∫πo H·ªçc T·∫≠p\n",
    "1. **Th·ª±c h√†nh th∆∞·ªùng xuy√™n**: Ch·∫°y code v√† th·ª≠ nghi·ªám v·ªõi c√°c tham s·ªë kh√°c nhau\n",
    "2. **ƒê·ªçc documentation**: Hi·ªÉu r√µ t·ª´ng parameter c·ªßa h√†m\n",
    "3. **Debug b·∫±ng visualization**: Lu√¥n hi·ªÉn th·ªã k·∫øt qu·∫£ trung gian\n",
    "4. **Th·ª≠ v·ªõi ·∫£nh ri√™ng**: √Åp d·ª•ng v√†o ·∫£nh c·ªßa ch√≠nh b·∫°n\n",
    "5. **K·∫øt h·ª£p k·ªπ thu·∫≠t**: Th·ª≠ k·∫øt h·ª£p nhi·ªÅu k·ªπ thu·∫≠t ƒë·ªÉ t·∫°o hi·ªáu ·ª©ng m·ªõi\n",
    "\n",
    "### Color Codes Reference (BGR)\n",
    "```python\n",
    "BLACK = (0, 0, 0)\n",
    "WHITE = (255, 255, 255)\n",
    "RED = (0, 0, 255)\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (255, 0, 0)\n",
    "YELLOW = (0, 255, 255)\n",
    "CYAN = (255, 255, 0)\n",
    "MAGENTA = (255, 0, 255)\n",
    "```\n",
    "\n",
    "### Common Issues v√† Solutions\n",
    "\n",
    "**1. ·∫¢nh kh√¥ng hi·ªÉn th·ªã:**\n",
    "- Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n file\n",
    "- ƒê·∫£m b·∫£o c√≥ `cv.waitKey(0)`\n",
    "\n",
    "**2. Kernel size error:**\n",
    "- Kernel ph·∫£i l√† s·ªë l·∫ª (3, 5, 7, ...)\n",
    "- Kernel ph·∫£i l√† tuple (x, y)\n",
    "\n",
    "**3. Color kh√¥ng ƒë√∫ng:**\n",
    "- Remember: OpenCV uses BGR, not RGB\n",
    "- Chuy·ªÉn ƒë·ªïi khi c·∫ßn: `cv.cvtColor(img, cv.COLOR_BGR2RGB)`\n",
    "\n",
    "---\n",
    "\n",
    "## K·∫æT LU·∫¨N\n",
    "\n",
    "Ch√∫c c√°c em h·ªçc t·ªët! H√£y th·ª±c h√†nh nhi·ªÅu v√† ƒë·ª´ng ng·∫°i th·ª≠ nghi·ªám. \n",
    "\n",
    "**Nh·ªõ r·∫±ng**: Computer Vision l√† v·ªÅ vi·ªác hi·ªÉu c√°ch m√°y t√≠nh \"nh√¨n\" th·∫ø gi·ªõi. M·ªói k·ªπ thu·∫≠t b·∫°n h·ªçc ƒë·ªÅu l√† m·ªôt c√¥ng c·ª• ƒë·ªÉ gi√∫p m√°y t√≠nh hi·ªÉu ·∫£nh t·ªët h∆°n.\n",
    "\n",
    "**Next Steps:**\n",
    "1. Ho√†n th√†nh t·∫•t c·∫£ b√†i t·∫≠p\n",
    "2. T√¨m hi·ªÉu tr∆∞·ªõc cho anh FastAPI\n",
    "\n",
    "---\n",
    "\n",
    "**GitHub**: https://github.com/jasmcaus/opencv-course"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
